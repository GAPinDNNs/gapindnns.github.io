---
layout: topic
title: Research
---

In the GAPinDNNs research group, we explore the interface of Geometry, Algebra, and Physics with Deep Neural Networks. Specifically, we use techniques and ideas from pure mathematics and theoretical physics to develop the foundations of deep learning and deep neural networks.

Deep learning, a cornerstone of modern machine learning, has achieved remarkable success across numerous applications by enabling computers to identify and replicate complex patterns directly from data. However, this success is mainly based en empirical observations. Despite its efficacy, the theoretical underpinnings of deep neural networks are not well-understood. This lack of understanding means that progress is driven mainly by trial and error, which is not only slow but also lacks the rigor necessary for applications requiring high reliability and interpretability, such as in medicine or law.

Our research is motivated by the assertion that adopting mathematical and physical theories could bridge this gap. These disciplines offer sophisticated tools for analyzing complex systems, which can be of great benefit for the study of machine learning. By integrating these tools, we aim towards a more systematic and interpretable approach to deep learning. This research program not only promises to make deep learning more efficient and robust but also opens up new possibilities for its application in areas where precision and trustworthiness are critical.

While our research requires sophisticated theoretical developments, it also brings forth numerous applications. In particular, any setting where data naturally belong to a curved space provides an arena for implementing ideas and results from geometric deep learning. Autonomous driving is a prime example. To identify traffic situations from different angles requires neural networks with rotational symmetry. Other potential applications include cosmological data analysis and climate pattern segmentation. 

