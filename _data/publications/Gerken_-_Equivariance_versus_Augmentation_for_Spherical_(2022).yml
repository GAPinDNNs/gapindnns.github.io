URL: https://proceedings.mlr.press/v162/gerken22a.html
abstract: |
  We analyze the role of rotational equivariance in convolutional neural networks
  (CNNs) applied to spherical images. We compare the performance of the group equivariant
  networks known as S2CNNs and standard non-equivariant CNNs trained with an increasing
  amount of data augmentation. The chosen architectures can be considered baseline
  references for the respective design paradigms. Our models are trained and evaluated
  on single or multiple items from the MNIST- or FashionMNIST dataset projected onto
  the sphere. For the task of image classification, which is inherently rotationally
  invariant, we find that by considerably increasing the amount of data augmentation
  and the size of the networks, it is possible for the standard CNNs to reach at least
  the same performance as the equivariant network. In contrast, for the inherently
  equivariant task of semantic segmentation, the non-equivariant networks are consistently
  outperformed by the equivariant networks with significantly fewer parameters. We
  also analyze and compare the inference latency and training times of the different
  networks, enabling detailed tradeoff considerations between equivariant architectures
  and data augmentation for practical problems.
author:
  - family: Gerken
    given: Jan E.
    first_author: true
  - family: Carlsson
    given: Oscar
  - family: Linander
    given: Hampus
  - family: Ohlsson
    given: Fredrik
  - family: Petersson
    given: Christoffer
  - family: Persson
    given: Daniel
issued: '2022-06-28'
publisher: ICML 2022
preprint:
  URL: https://arxiv.org/abs/2202.03990
  name: arXiv
title: Equivariance versus Augmentation for Spherical Images
type: paper-conference
tags:
  - SCV
  - ENN

