title: 'Looking at the posterior: accuracy and uncertainty of neural-network predictions'
id: Linander_-_Looking_at_the_posterior_accuracy_(2023)
author:
  - family: Linander
    given: Hampus
  - family: Balabanov
    given: Oleksandr
  - family: Yang
    given: Henry
  - family: Mehlig
    given: Bernhard
issued: "2023-11-17"
DOI: 10.1088/2632-2153/ad0ab4
URL: https://iopscience.iop.org/article/10.1088/2632-2153/ad0ab4
abstract: |
  Bayesian inference can quantify uncertainty in the
  predictions of neural networks using posterior distributions for model parameters
  and network output. By looking at these posterior distributions, one can separate
  the origin of uncertainty into aleatoric and epistemic contributions. One goal
  of uncertainty quantification is to inform on prediction accuracy. Here we show
  that prediction accuracy depends on both epistemic and aleatoric uncertainty in
  an intricate fashion that cannot be understood in terms of marginalized uncertainty
  distributions alone. How the accuracy relates to epistemic and aleatoric uncertainties
  depends not only on the model architecture, but also on the properties of the
  dataset. We discuss the significance of these results for active learning and
  introduce a novel acquisition function that outperforms common uncertainty-based
  methods. To arrive at our results, we approximated the posteriors using deep ensembles,
  for fully-connected, convolutional and attention-based neural networks.
publisher: 'Machine Learning: Science and Technology'
type: article-journal
tags: 
  - XAI
  - UQ
